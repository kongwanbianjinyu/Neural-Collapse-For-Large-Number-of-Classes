{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardmax(W,H):\n",
    "  d_dist = W @ H.T\n",
    "  wh = torch.diag(d_dist)\n",
    "  matrix = d_dist - wh.unsqueeze(1).repeat((1,W.shape[0]))\n",
    "  for i in range(W.shape[0]):\n",
    "      matrix[i, i] = -np.inf\n",
    "  max = torch.max(matrix)\n",
    "  return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(W, H, alpha=0.1, tol=1e-6, max_iter=500000):\n",
    "    \"\"\"\n",
    "    Use gradient descent to minimize the objective function.\n",
    "    \"\"\"\n",
    "    lr_sched = np.linspace(0, alpha, num=max_iter)\n",
    "    lr_sched = lr_sched[::-1]\n",
    "    W = torch.autograd.Variable(W, requires_grad=True)\n",
    "    H = torch.autograd.Variable(H, requires_grad=True)\n",
    "    for i in range(max_iter):\n",
    "        f = hardmax(W, H)\n",
    "        # f = torch.nn.functional.cross_entropy(W@H.T*1, torch.arange(0, W.shape[0]).type(torch.LongTensor).to(W.device))\n",
    "        f.backward()\n",
    "        if torch.norm(W.grad) < tol and torch.norm(H.grad):\n",
    "            break\n",
    "        with torch.no_grad():\n",
    "            W -= lr_sched[i] * W.grad\n",
    "            W /= torch.norm(W, dim=1, keepdim=True)\n",
    "            W.grad.zero_()\n",
    "            H -= lr_sched[i] * H.grad\n",
    "            H /= torch.norm(H, dim=1, keepdim=True)\n",
    "            H.grad.zero_()\n",
    "        if i%5000 == 0:\n",
    "          print(\"iteration \" + str(i).zfill(7) +\" lr: %.3f\"%lr_sched[i]+\" f_value: %.8f\" %f.item() + \" max difference: %.5f\"%torch.max(torch.norm(W-H, dim=1)).item())\n",
    "    return f, W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: 22, K: 100\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './WWT_matrix/d22_K100.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/local/storage1/jiang.2880/NCLargeNumClasses/hardmax_problem.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcse-cnc197016s.coeit.osu.edu/local/storage1/jiang.2880/NCLargeNumClasses/hardmax_problem.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39md: \u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m, K: \u001b[39m\u001b[39m{\u001b[39;00mK\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-cnc197016s.coeit.osu.edu/local/storage1/jiang.2880/NCLargeNumClasses/hardmax_problem.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#W = torch.randn((K, d)).to(device)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcse-cnc197016s.coeit.osu.edu/local/storage1/jiang.2880/NCLargeNumClasses/hardmax_problem.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m W_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./WWT_matrix/d22_K100.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-cnc197016s.coeit.osu.edu/local/storage1/jiang.2880/NCLargeNumClasses/hardmax_problem.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m W \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(W_np)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-cnc197016s.coeit.osu.edu/local/storage1/jiang.2880/NCLargeNumClasses/hardmax_problem.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m W \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(W, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/pytorch/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './WWT_matrix/d22_K100.npy'"
     ]
    }
   ],
   "source": [
    "#d_list = [3]#[3,4,8,7,6,5]\n",
    "#K_list = [12]#[12,120,240,56,27,16]\n",
    "#d_K_pair = [(7,56), (6,27), (5,16), (4, 120), (8,240)]\n",
    "d_K_pair = [(22,100)] #[(22,100),(21,162)]\n",
    "cos_list = []\n",
    "lr = 0.1\n",
    "device = \"cuda:2\"\n",
    "for (d,K) in d_K_pair:\n",
    "    print(f\"d: {d}, K: {K}\")\n",
    "    W = torch.randn((K, d)).to(device)\n",
    "    #W_np = np.load(\"./WWT_matrix/d22_K100.npy\")\n",
    "    #W = torch.tensor(W_np).to(device)\n",
    "    W /= torch.norm(W, dim=1, keepdim=True)\n",
    "    H = W\n",
    "\n",
    "    init_f= hardmax(W, H)\n",
    "    print('init_f: ', init_f)\n",
    "    minimizer, W, H = minimize(W, H, alpha=lr)\n",
    "\n",
    "\n",
    "    WWT = (W @ W.T).detach().cpu().numpy()\n",
    "    with open(f'./WWT_matrix/d{d}_K{K}.npy', 'wb') as f:\n",
    "      np.save(f, WWT)\n",
    "\n",
    "    for i in range(WWT.shape[0]):\n",
    "        WWT[i,i] = -np.inf\n",
    "    print(\"max cosine value:\", np.max(WWT))\n",
    "    cos_list.append(np.max(WWT))\n",
    "\n",
    "print(cos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
